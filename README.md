# Racism-and-Offensive-Text-Detection

<p>
Link to the Google Colab code to the main code: https://colab.research.google.com/drive/1T-9GJBWCgE5QxDgEgSJ6p9YQYcYosTx7?usp=sharing <br>
Link to the Google Colab code to the deployment based code: https://colab.research.google.com/drive/1KHUlQZHDxMm9iEGz2TLFJQt6w9K5AKBD#scrollTo=SaketWGJWZ6D<br>
Here, I've created models which predict whether a given sentence contains some hate or offensive overtone. The logistic regression classifier has done well in both the cases.<br>
</p>
We get an accuracy of around 94% in both the cases of hate and offensive content detection.<br>
This model has been deployed using Flask. Other frameworks used include
<ol>
  <li>HTML</li>
  <li>CSS</li>
  <li>Python</li>
</ol>
The code for the deployed model is included here as well along with all the other frameworks as well.<br>
However, in the jupyter notebook, the models are pickled and available in this repository. The other methods I have used here (only in the jupyter notebook) include: Naive Bayes, Decision Tree, KNN and Random Forest.

## Site functionality

<p>
  The main page would look something like this: <br>
  ![image](https://github.com/PRITH-S07/Racistometer/blob/main/page_1.JPG)



